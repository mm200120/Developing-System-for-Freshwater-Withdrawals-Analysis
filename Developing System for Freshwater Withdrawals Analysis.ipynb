{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b8d989-37e2-4dae-81d0-386313e7990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI Libraries Installed Successfully!\n"
     ]
    }
   ],
   "source": [
    "#Install Required Libraries\n",
    "!pip install pandas numpy scikit-learn tensorflow xgboost prophet pyod plotly seaborn matplotlib shap -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\" AI Libraries Installed Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07a659ad-73f3-4861-8f8f-2f7f3b834261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data Processor\n",
    "class WaterCrisisAIDataProcessor:\n",
    "    \"\"\"\n",
    "    AI-focused data processor with advanced feature engineering\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.df = None\n",
    "        self.df_features = None\n",
    "        self.country_metadata = {}\n",
    "        \n",
    "    def load_and_engineer_features(self):\n",
    "        \"\"\"Load data and create AI-ready features\"\"\"\n",
    "        print(\"Loading data for AI analysis...\")\n",
    "        \n",
    "        # Load data\n",
    "        self.df = pd.read_csv(self.filepath, skiprows=4)\n",
    "        self.df.columns = [col.strip().replace('\"', '') for col in self.df.columns]\n",
    "        \n",
    "        # Get year columns\n",
    "        year_cols = [col for col in self.df.columns if col.isdigit()]\n",
    "        self.years = [int(y) for y in year_cols]\n",
    "        \n",
    "        # Create AI features\n",
    "        self._create_ai_features()\n",
    "        print(f\" Data loaded with {len(self.df_features)} AI features\")\n",
    "        \n",
    "        return self.df_features\n",
    "    \n",
    "    def _create_ai_features(self):\n",
    "        \"\"\"Create comprehensive features for AI models\"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            country = row['Country Name']\n",
    "            country_code = row['Country Code']\n",
    "            \n",
    "            # Extract time series data\n",
    "            ts_data = []\n",
    "            valid_years = []\n",
    "            for year in self.years:\n",
    "                value = row.get(str(year))\n",
    "                if pd.notna(value):\n",
    "                    ts_data.append(float(value))\n",
    "                    valid_years.append(year)\n",
    "            \n",
    "            if len(ts_data) < 10:  # Skip countries with insufficient data\n",
    "                continue\n",
    "            \n",
    "            # Create features dictionary\n",
    "            features = {\n",
    "                'country': country,\n",
    "                'country_code': country_code,\n",
    "                'timeseries': ts_data,\n",
    "                'years': valid_years,\n",
    "                'latest_value': ts_data[-1] if ts_data else np.nan,\n",
    "                'first_value': ts_data[0] if ts_data else np.nan,\n",
    "                'trend_slope': self._calculate_trend_slope(ts_data, valid_years),\n",
    "                'volatility': np.std(ts_data) if len(ts_data) > 1 else 0,\n",
    "                'max_value': np.max(ts_data),\n",
    "                'min_value': np.min(ts_data),\n",
    "                'mean_value': np.mean(ts_data),\n",
    "                'median_value': np.median(ts_data),\n",
    "                'pct_change_10yr': self._calculate_percent_change(ts_data, valid_years, 10),\n",
    "                'pct_change_20yr': self._calculate_percent_change(ts_data, valid_years, 20),\n",
    "                'crisis_risk_score': self._calculate_crisis_risk(ts_data, valid_years),\n",
    "                'is_extreme_high': 1 if ts_data[-1] > 100 else 0,\n",
    "                'is_high_stress': 1 if ts_data[-1] > 50 else 0,\n",
    "                'is_low_stress': 1 if ts_data[-1] < 10 else 0,\n",
    "                'acceleration': self._calculate_acceleration(ts_data, valid_years)\n",
    "            }\n",
    "            \n",
    "            # Add statistical features\n",
    "            features.update(self._calculate_statistical_features(ts_data))\n",
    "            \n",
    "            features_list.append(features)\n",
    "            \n",
    "            # Store metadata\n",
    "            self.country_metadata[country] = features\n",
    "        \n",
    "        self.df_features = pd.DataFrame(features_list)\n",
    "        return self.df_features\n",
    "    \n",
    "    def _calculate_trend_slope(self, values, years):\n",
    "        \"\"\"Calculate linear trend slope\"\"\"\n",
    "        if len(values) < 2:\n",
    "            return 0\n",
    "        x = np.array(years)\n",
    "        y = np.array(values)\n",
    "        slope = np.polyfit(x, y, 1)[0]\n",
    "        return slope\n",
    "    \n",
    "    def _calculate_percent_change(self, values, years, period_years):\n",
    "        \"\"\"Calculate percentage change over specified period\"\"\"\n",
    "        if len(values) < 2:\n",
    "            return 0\n",
    "        \n",
    "        recent_idx = -1\n",
    "        past_idx = max(-len(values), -period_years - 1)\n",
    "        \n",
    "        if past_idx >= -len(values):\n",
    "            past_value = values[past_idx]\n",
    "            recent_value = values[recent_idx]\n",
    "            if past_value != 0:\n",
    "                return ((recent_value - past_value) / past_value) * 100\n",
    "        return 0\n",
    "    \n",
    "    def _calculate_crisis_risk(self, values, years):\n",
    "        \"\"\"Calculate risk score (0-100) for water crisis\"\"\"\n",
    "        if len(values) < 5:\n",
    "            return 0\n",
    "        \n",
    "        risk_score = 0\n",
    "        \n",
    "        # Latest value weight (40%)\n",
    "        latest = values[-1]\n",
    "        if latest > 100:\n",
    "            risk_score += 40\n",
    "        elif latest > 75:\n",
    "            risk_score += 30\n",
    "        elif latest > 50:\n",
    "            risk_score += 20\n",
    "        elif latest > 25:\n",
    "            risk_score += 10\n",
    "        \n",
    "        # Trend weight (30%)\n",
    "        trend = self._calculate_trend_slope(values, years)\n",
    "        if trend > 2:\n",
    "            risk_score += 30\n",
    "        elif trend > 1:\n",
    "            risk_score += 20\n",
    "        elif trend > 0.5:\n",
    "            risk_score += 10\n",
    "        \n",
    "        # Volatility weight (15%)\n",
    "        volatility = np.std(values[-5:]) if len(values) >= 5 else np.std(values)\n",
    "        if volatility > 15:\n",
    "            risk_score += 15\n",
    "        elif volatility > 10:\n",
    "            risk_score += 10\n",
    "        elif volatility > 5:\n",
    "            risk_score += 5\n",
    "        \n",
    "        # Acceleration weight (15%)\n",
    "        acceleration = self._calculate_acceleration(values, years)\n",
    "        if acceleration > 1:\n",
    "            risk_score += 15\n",
    "        elif acceleration > 0.5:\n",
    "            risk_score += 10\n",
    "        elif acceleration > 0:\n",
    "            risk_score += 5\n",
    "        \n",
    "        return min(100, risk_score)\n",
    "    \n",
    "    def _calculate_acceleration(self, values, years):\n",
    "        \"\"\"Calculate acceleration of change\"\"\"\n",
    "        if len(values) < 10:\n",
    "            return 0\n",
    "        \n",
    "        recent_slope = self._calculate_trend_slope(values[-5:], years[-5:]) if len(values) >= 5 else 0\n",
    "        earlier_slope = self._calculate_trend_slope(values[-10:-5], years[-10:-5]) if len(values) >= 10 else 0\n",
    "        \n",
    "        return recent_slope - earlier_slope\n",
    "    \n",
    "    def _calculate_statistical_features(self, values):\n",
    "        \"\"\"Calculate various statistical features\"\"\"\n",
    "        if len(values) < 3:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'skewness': pd.Series(values).skew(),\n",
    "            'kurtosis': pd.Series(values).kurtosis(),\n",
    "            'q1': np.percentile(values, 25),\n",
    "            'q3': np.percentile(values, 75),\n",
    "            'iqr': np.percentile(values, 75) - np.percentile(values, 25),\n",
    "            'cv': np.std(values) / np.mean(values) if np.mean(values) != 0 else 0\n",
    "        }\n",
    "    \n",
    "    def get_country_features(self, country_name):\n",
    "        \"\"\"Get features for specific country\"\"\"\n",
    "        return self.df_features[self.df_features['country'] == country_name]\n",
    "    \n",
    "    def get_risk_categories(self):\n",
    "        \"\"\"Categorize countries by risk level\"\"\"\n",
    "        self.df_features['risk_category'] = pd.cut(\n",
    "            self.df_features['crisis_risk_score'],\n",
    "            bins=[0, 25, 50, 75, 100],\n",
    "            labels=['Low', 'Medium', 'High', 'Critical']\n",
    "        )\n",
    "        return self.df_features['risk_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ccffe-5347-4c49-a403-eaf846796582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water Crisis Predictor - Machine Learning Models\n",
    "class WaterCrisisPredictor:\n",
    "    \"\"\"\n",
    "    AI models for predicting water crises\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_processor):\n",
    "        self.processor = data_processor\n",
    "        self.df_features = data_processor.df_features\n",
    "        self.models = {}\n",
    "        self.predictions = {}\n",
    "        \n",
    "        from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "        from sklearn.cluster import KMeans, DBSCAN\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.decomposition import PCA\n",
    "        from pyod.models.iforest import IForest\n",
    "        from xgboost import XGBClassifier\n",
    "        \n",
    "        self.RandomForestClassifier = RandomForestClassifier\n",
    "        self.GradientBoostingClassifier = GradientBoostingClassifier\n",
    "        self.KMeans = KMeans\n",
    "        self.DBSCAN = DBSCAN\n",
    "        self.StandardScaler = StandardScaler\n",
    "        self.PCA = PCA\n",
    "        self.IForest = IForest\n",
    "        self.XGBClassifier = XGBClassifier\n",
    "    \n",
    "    def predict_crisis_risk(self, forecast_years=5):\n",
    "        \"\"\"\n",
    "        Predict which countries will face water crises in next N years\n",
    "        \"\"\"\n",
    "        print(\" Predicting water crisis risks...\")\n",
    "        \n",
    "        # Prepare features for prediction\n",
    "        X = self._prepare_prediction_features()\n",
    "        \n",
    "        # Create labels (crisis = 1 if risk_score > 70 or value > 100)\n",
    "        y = (self.df_features['crisis_risk_score'] > 70).astype(int)\n",
    "        \n",
    "        # Train Random Forest\n",
    "        rf_model = self.RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            max_depth=10\n",
    "        )\n",
    "        rf_model.fit(X, y)\n",
    "        \n",
    "        # Train XGBoost\n",
    "        xgb_model = self.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.1\n",
    "        )\n",
    "        xgb_model.fit(X, y)\n",
    "        \n",
    "        # Store models\n",
    "        self.models['random_forest'] = rf_model\n",
    "        self.models['xgboost'] = xgb_model\n",
    "        \n",
    "        # Make predictions\n",
    "        rf_predictions = rf_model.predict_proba(X)[:, 1]\n",
    "        xgb_predictions = xgb_model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        ensemble_pred = (rf_predictions + xgb_predictions) / 2\n",
    "        \n",
    "        # Add predictions to dataframe\n",
    "        self.df_features['crisis_probability'] = ensemble_pred\n",
    "        self.df_features['predicted_crisis'] = (ensemble_pred > 0.7).astype(int)\n",
    "        \n",
    "        # Identify high-risk countries\n",
    "        high_risk = self.df_features[\n",
    "            (self.df_features['crisis_probability'] > 0.7) & \n",
    "            (self.df_features['latest_value'] > 50)\n",
    "        ].sort_values('crisis_probability', ascending=False)\n",
    "        \n",
    "        # Forecast future values using trend projection\n",
    "        self._forecast_future_values(forecast_years)\n",
    "        \n",
    "        print(f\"Identified {len(high_risk)} high-risk countries\")\n",
    "        \n",
    "        return high_risk\n",
    "    \n",
    "    def _prepare_prediction_features(self):\n",
    "        \"\"\"Prepare numerical features for ML models\"\"\"\n",
    "        feature_cols = [\n",
    "            'latest_value', 'trend_slope', 'volatility', 'max_value',\n",
    "            'mean_value', 'pct_change_10yr', 'pct_change_20yr',\n",
    "            'crisis_risk_score', 'acceleration', 'skewness', 'kurtosis',\n",
    "            'iqr', 'cv'\n",
    "        ]\n",
    "        \n",
    "        # Fill missing values\n",
    "        X = self.df_features[feature_cols].fillna(0)\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = self.StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        return X_scaled\n",
    "    \n",
    "    def _forecast_future_values(self, years_ahead):\n",
    "        \"\"\"Forecast future water withdrawal values\"\"\"\n",
    "        forecasts = []\n",
    "        \n",
    "        for idx, row in self.df_features.iterrows():\n",
    "            trend = row['trend_slope']\n",
    "            current = row['latest_value']\n",
    "            acceleration = row['acceleration']\n",
    "            \n",
    "            # Simple linear forecast with acceleration\n",
    "            forecast_vals = []\n",
    "            for year in range(1, years_ahead + 1):\n",
    "                # Quadratic projection: current + trend*year + 0.5*acceleration*year^2\n",
    "                forecast = current + trend*year + 0.5*acceleration*(year**2)\n",
    "                forecast_vals.append(max(0, forecast))  # Don't go below 0\n",
    "            \n",
    "            forecasts.append({\n",
    "                'country': row['country'],\n",
    "                'current_value': current,\n",
    "                f'forecast_{years_ahead}yr': forecast_vals[-1] if forecast_vals else current,\n",
    "                'forecast_trajectory': forecast_vals\n",
    "            })\n",
    "        \n",
    "        self.forecasts_df = pd.DataFrame(forecasts)\n",
    "        \n",
    "        # Merge with main dataframe\n",
    "        self.df_features = self.df_features.merge(\n",
    "            self.forecasts_df[['country', f'forecast_{years_ahead}yr']],\n",
    "            on='country',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Identify countries where forecast exceeds 100%\n",
    "        self.df_features['will_exceed_100'] = (\n",
    "            self.df_features[f'forecast_{years_ahead}yr'] > 100\n",
    "        ).astype(int)\n",
    "    \n",
    "    def cluster_countries(self, n_clusters=5):\n",
    "        \"\"\"\n",
    "        Cluster countries by water usage patterns using K-means\n",
    "        \"\"\"\n",
    "        print(f\" Clustering countries into {n_clusters} groups...\")\n",
    "        \n",
    "        # Prepare clustering features\n",
    "        cluster_features = [\n",
    "            'latest_value', 'trend_slope', 'volatility', 'mean_value',\n",
    "            'pct_change_10yr', 'crisis_risk_score', 'skewness'\n",
    "        ]\n",
    "        \n",
    "        X_cluster = self.df_features[cluster_features].fillna(0)\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = self.StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_cluster)\n",
    "        \n",
    "        # Apply PCA for visualization\n",
    "        pca = self.PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # Apply K-means clustering\n",
    "        kmeans = self.KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        # Add clusters to dataframe\n",
    "        self.df_features['cluster'] = clusters\n",
    "        self.df_features['pca_x'] = X_pca[:, 0]\n",
    "        self.df_features['pca_y'] = X_pca[:, 1]\n",
    "        \n",
    "        # Analyze cluster characteristics\n",
    "        cluster_analysis = self._analyze_clusters(clusters)\n",
    "        \n",
    "        return clusters, cluster_analysis\n",
    "    \n",
    "    def _analyze_clusters(self, clusters):\n",
    "        \"\"\"Analyze characteristics of each cluster\"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for cluster_id in np.unique(clusters):\n",
    "            cluster_data = self.df_features[self.df_features['cluster'] == cluster_id]\n",
    "            \n",
    "            analysis[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'avg_withdrawal': cluster_data['latest_value'].mean(),\n",
    "                'avg_trend': cluster_data['trend_slope'].mean(),\n",
    "                'avg_risk': cluster_data['crisis_risk_score'].mean(),\n",
    "                'countries': cluster_data['country'].tolist()[:10],  # First 10 countries\n",
    "                'characteristics': self._describe_cluster(cluster_data)\n",
    "            }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _describe_cluster(self, cluster_data):\n",
    "        \"\"\"Generate natural language description of cluster\"\"\"\n",
    "        avg_withdrawal = cluster_data['latest_value'].mean()\n",
    "        avg_trend = cluster_data['trend_slope'].mean()\n",
    "        avg_risk = cluster_data['crisis_risk_score'].mean()\n",
    "        \n",
    "        if avg_withdrawal > 100:\n",
    "            desc = \"Extreme water stress countries\"\n",
    "        elif avg_withdrawal > 50:\n",
    "            desc = \"High water stress countries\"\n",
    "        elif avg_withdrawal > 25:\n",
    "            desc = \"Moderate water use countries\"\n",
    "        else:\n",
    "            desc = \"Low water use countries\"\n",
    "        \n",
    "        if avg_trend > 1:\n",
    "            desc += \" with rapidly increasing withdrawals\"\n",
    "        elif avg_trend > 0:\n",
    "            desc += \" with slowly increasing withdrawals\"\n",
    "        elif avg_trend < -1:\n",
    "            desc += \" with rapidly decreasing withdrawals\"\n",
    "        else:\n",
    "            desc += \" with stable or decreasing withdrawals\"\n",
    "        \n",
    "        if avg_risk > 75:\n",
    "            desc += \" (CRITICAL RISK)\"\n",
    "        elif avg_risk > 50:\n",
    "            desc += \" (HIGH RISK)\"\n",
    "        \n",
    "        return desc\n",
    "    \n",
    "    def detect_anomalies(self, contamination=0.1):\n",
    "        \"\"\"\n",
    "        Detect unusual changes in withdrawal patterns using Isolation Forest\n",
    "        \"\"\"\n",
    "        print(\" Detecting anomalous patterns...\")\n",
    "        \n",
    "        # Features for anomaly detection\n",
    "        anomaly_features = [\n",
    "            'latest_value', 'trend_slope', 'volatility', \n",
    "            'pct_change_10yr', 'acceleration', 'skewness'\n",
    "        ]\n",
    "        \n",
    "        X_anomaly = self.df_features[anomaly_features].fillna(0)\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = self.StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_anomaly)\n",
    "        \n",
    "        # Apply Isolation Forest\n",
    "        iso_forest = self.IForest(contamination=contamination, random_state=42)\n",
    "        anomalies = iso_forest.fit_predict(X_scaled)\n",
    "        \n",
    "        # -1 for anomalies, 1 for normal\n",
    "        self.df_features['is_anomaly'] = (anomalies == -1).astype(int)\n",
    "        \n",
    "        # Get anomaly scores\n",
    "        self.df_features['anomaly_score'] = iso_forest.decision_function(X_scaled)\n",
    "        \n",
    "        anomalous_countries = self.df_features[\n",
    "            self.df_features['is_anomaly'] == 1\n",
    "        ]['country'].tolist()\n",
    "        \n",
    "        print(f\" Detected {len(anomalous_countries)} anomalous countries\")\n",
    "        \n",
    "        return anomalous_countries\n",
    "    \n",
    "    def get_recommendations(self, country_name, n_recommendations=5):\n",
    "        \"\"\"\n",
    "        Recommend water conservation strategies based on similar countries\n",
    "        \"\"\"\n",
    "        if country_name not in self.df_features['country'].values:\n",
    "            return f\"Country {country_name} not found in data\"\n",
    "        \n",
    "        # Get target country features\n",
    "        target_country = self.df_features[\n",
    "            self.df_features['country'] == country_name\n",
    "        ].iloc[0]\n",
    "        \n",
    "        # Find similar countries (same cluster, similar risk level)\n",
    "        cluster_id = target_country['cluster']\n",
    "        similar_countries = self.df_features[\n",
    "            (self.df_features['cluster'] == cluster_id) &\n",
    "            (self.df_features['country'] != country_name)\n",
    "        ]\n",
    "        \n",
    "        if len(similar_countries) == 0:\n",
    "            # Find countries with similar withdrawal levels\n",
    "            target_value = target_country['latest_value']\n",
    "            similar_countries = self.df_features[\n",
    "                (self.df_features['country'] != country_name) &\n",
    "                (abs(self.df_features['latest_value'] - target_value) < 10)\n",
    "            ]\n",
    "        \n",
    "        # Sort by similarity (closest in latest_value and trend)\n",
    "        similar_countries['similarity_score'] = similar_countries.apply(\n",
    "            lambda row: 1 / (1 + abs(row['latest_value'] - target_country['latest_value']) + \n",
    "                            abs(row['trend_slope'] - target_country['trend_slope'])),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        similar_countries = similar_countries.sort_values(\n",
    "            'similarity_score', ascending=False\n",
    "        ).head(n_recommendations)\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = self._generate_recommendation_text(\n",
    "            target_country, similar_countries\n",
    "        )\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _generate_recommendation_text(self, target_country, similar_countries):\n",
    "        \"\"\"Generate natural language recommendations\"\"\"\n",
    "        country_name = target_country['country']\n",
    "        current_value = target_country['latest_value']\n",
    "        risk_score = target_country['crisis_risk_score']\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # Base recommendation based on current status\n",
    "        if current_value > 100:\n",
    "            recommendations.append(f\" **CRITICAL**: {country_name}'s water withdrawals exceed 100% of internal resources. Immediate action required.\")\n",
    "            recommendations.append(\" **Recommendation**: Implement emergency water conservation measures, explore alternative water sources, and consider importing water.\")\n",
    "        elif current_value > 75:\n",
    "            recommendations.append(f\" **HIGH STRESS**: {country_name} is using over 75% of its internal water resources.\")\n",
    "            recommendations.append(\" **Recommendation**: Strengthen water governance, invest in water-saving technologies, and promote water recycling.\")\n",
    "        elif current_value > 50:\n",
    "            recommendations.append(f\" **MEDIUM-HIGH**: {country_name} uses over 50% of internal water resources.\")\n",
    "            recommendations.append(\"**Recommendation**: Improve irrigation efficiency, fix water distribution leaks, and implement water pricing reforms.\")\n",
    "        else:\n",
    "            recommendations.append(f\" **MANAGEABLE**: {country_name}'s water use is currently sustainable.\")\n",
    "            recommendations.append(\" **Recommendation**: Continue monitoring and invest in long-term water infrastructure.\")\n",
    "        \n",
    "        # Add learning from similar countries\n",
    "        recommendations.append(\"\\n**Learn from similar countries**:\")\n",
    "        \n",
    "        for idx, row in similar_countries.iterrows():\n",
    "            similar_country = row['country']\n",
    "            similar_value = row['latest_value']\n",
    "            similar_trend = row['trend_slope']\n",
    "            \n",
    "            if similar_trend < 0:  # Decreasing trend\n",
    "                rec = f\"  ‚Ä¢ {similar_country} reduced withdrawals from {similar_value + abs(similar_trend)*5:.1f}% to {similar_value:.1f}%\"\n",
    "                rec += \" through efficient water management policies.\"\n",
    "            else:\n",
    "                rec = f\"  ‚Ä¢ {similar_country} manages {similar_value:.1f}% withdrawals\"\n",
    "                rec += \" with comprehensive water governance framework.\"\n",
    "            \n",
    "            recommendations.append(rec)\n",
    "        \n",
    "        # Specific strategies based on cluster\n",
    "        cluster_id = target_country['cluster']\n",
    "        cluster_strategies = {\n",
    "            0: \"Focus on agricultural water efficiency (drip irrigation)\",\n",
    "            1: \"Industrial water recycling and reuse programs\",\n",
    "            2: \"Urban water demand management and leak reduction\",\n",
    "            3: \"Integrated water resource management across sectors\",\n",
    "            4: \"Climate-resilient water infrastructure investment\"\n",
    "        }\n",
    "        \n",
    "        if cluster_id in cluster_strategies:\n",
    "            recommendations.append(f\"\\n **Cluster-specific strategy**: {cluster_strategies[cluster_id]}\")\n",
    "        \n",
    "        return \"\\n\".join(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cacc39-51c7-4e2d-811f-740d27b9a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Dashboard\n",
    "class WaterCrisisVisualizer:\n",
    "    \"\"\"\n",
    "    Advanced visualizations for AI insights\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "        self.df_features = predictor.df_features\n",
    "        \n",
    "    def plot_risk_map(self):\n",
    "        \"\"\"Create global risk map\"\"\"\n",
    "        import plotly.express as px\n",
    "        import plotly.graph_objects as go\n",
    "        \n",
    "        # Create risk categories for coloring\n",
    "        risk_bins = [0, 25, 50, 75, 100]\n",
    "        risk_labels = ['Low (0-25)', 'Medium (26-50)', 'High (51-75)', 'Critical (76-100)']\n",
    "        self.df_features['risk_category'] = pd.cut(\n",
    "            self.df_features['crisis_risk_score'],\n",
    "            bins=risk_bins,\n",
    "            labels=risk_labels\n",
    "        )\n",
    "        \n",
    "        fig = px.choropleth(\n",
    "            self.df_features,\n",
    "            locations=\"country\",\n",
    "            locationmode=\"country names\",\n",
    "            color=\"risk_category\",\n",
    "            hover_name=\"country\",\n",
    "            hover_data=[\"latest_value\", \"crisis_risk_score\", \"crisis_probability\"],\n",
    "            color_discrete_map={\n",
    "                'Low (0-25)': 'green',\n",
    "                'Medium (26-50)': 'yellow',\n",
    "                'High (51-75)': 'orange',\n",
    "                'Critical (76-100)': 'red'\n",
    "            },\n",
    "            title=\" Global Water Crisis Risk Map\",\n",
    "            labels={'risk_category': 'Risk Level'}\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=600)\n",
    "        return fig\n",
    "    \n",
    "    def plot_cluster_analysis(self):\n",
    "        \"\"\"Visualize country clusters\"\"\"\n",
    "        import plotly.express as px\n",
    "        \n",
    "        fig = px.scatter(\n",
    "            self.df_features,\n",
    "            x='pca_x',\n",
    "            y='pca_y',\n",
    "            color='cluster',\n",
    "            hover_name='country',\n",
    "            hover_data=['latest_value', 'trend_slope', 'crisis_risk_score'],\n",
    "            title=' Country Clusters by Water Usage Patterns',\n",
    "            labels={\n",
    "                'pca_x': 'PCA Component 1',\n",
    "                'pca_y': 'PCA Component 2',\n",
    "                'cluster': 'Cluster',\n",
    "                'latest_value': 'Current Withdrawal (%)'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')))\n",
    "        fig.update_layout(height=500)\n",
    "        return fig\n",
    "    \n",
    "    def plot_crisis_predictions(self):\n",
    "        \"\"\"Visualize crisis predictions\"\"\"\n",
    "        import plotly.graph_objects as go\n",
    "        \n",
    "        # Sort by crisis probability\n",
    "        df_sorted = self.df_features.sort_values('crisis_probability', ascending=False).head(20)\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Bar(\n",
    "            x=df_sorted['crisis_probability'],\n",
    "            y=df_sorted['country'],\n",
    "            orientation='h',\n",
    "            marker_color=df_sorted['crisis_probability'],\n",
    "            text=df_sorted['crisis_probability'].round(3),\n",
    "            textposition='auto',\n",
    "            hovertemplate=\"<b>%{y}</b><br>Crisis Probability: %{x:.3f}<br>Current Withdrawal: %{customdata[0]:.1f}%<extra></extra>\",\n",
    "            customdata=df_sorted[['latest_value']]\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=' Top 20 Countries Predicted for Water Crisis',\n",
    "            xaxis_title='Crisis Probability (0-1)',\n",
    "            yaxis_title='Country',\n",
    "            height=600,\n",
    "            yaxis={'categoryorder': 'total ascending'},\n",
    "            coloraxis=dict(colorscale='RdYlGn_r')\n",
    "        )\n",
    "        \n",
    "        # Add threshold line\n",
    "        fig.add_vline(x=0.7, line_dash=\"dash\", line_color=\"red\", \n",
    "                     annotation_text=\"High Risk Threshold\", \n",
    "                     annotation_position=\"top right\")\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_anomaly_detection(self):\n",
    "        \"\"\"Visualize detected anomalies\"\"\"\n",
    "        import plotly.graph_objects as go\n",
    "        from plotly.subplots import make_subplots\n",
    "        \n",
    "        anomalous = self.df_features[self.df_features['is_anomaly'] == 1]\n",
    "        normal = self.df_features[self.df_features['is_anomaly'] == 0]\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=('Anomalous Countries', 'Normal Countries'),\n",
    "            column_widths=[0.5, 0.5]\n",
    "        )\n",
    "        \n",
    "        # Anomalous countries\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=anomalous['latest_value'],\n",
    "                y=anomalous['trend_slope'],\n",
    "                mode='markers',\n",
    "                name='Anomalous',\n",
    "                marker=dict(size=10, color='red', symbol='x'),\n",
    "                text=anomalous['country'],\n",
    "                hovertemplate=\"<b>%{text}</b><br>Withdrawal: %{x:.1f}%<br>Trend: %{y:.2f}<extra></extra>\"\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Normal countries\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=normal['latest_value'],\n",
    "                y=normal['trend_slope'],\n",
    "                mode='markers',\n",
    "                name='Normal',\n",
    "                marker=dict(size=8, color='blue', opacity=0.6),\n",
    "                text=normal['country'],\n",
    "                hovertemplate=\"<b>%{text}</b><br>Withdrawal: %{x:.1f}%<br>Trend: %{y:.2f}<extra></extra>\"\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Current Withdrawal (%)\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Current Withdrawal (%)\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Trend Slope\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Trend Slope\", row=1, col=2)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=' Anomaly Detection in Water Withdrawal Patterns',\n",
    "            height=500,\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_trajectory_forecast(self, country_name, years_ahead=10):\n",
    "        \"\"\"Plot forecast trajectory for a country\"\"\"\n",
    "        import plotly.graph_objects as go\n",
    "        \n",
    "        country_data = self.predictor.processor.country_metadata.get(country_name)\n",
    "        if not country_data:\n",
    "            return None\n",
    "        \n",
    "        years = country_data['years']\n",
    "        values = country_data['timeseries']\n",
    "        \n",
    "        # Create forecast\n",
    "        trend = country_data['trend_slope']\n",
    "        current = values[-1]\n",
    "        acceleration = country_data.get('acceleration', 0)\n",
    "        \n",
    "        forecast_years = list(range(years[-1] + 1, years[-1] + years_ahead + 1))\n",
    "        forecast_values = []\n",
    "        \n",
    "        for i, year in enumerate(forecast_years, 1):\n",
    "            forecast = current + trend*i + 0.5*acceleration*(i**2)\n",
    "            forecast_values.append(max(0, forecast))\n",
    "        \n",
    "        # Combine historical and forecast\n",
    "        all_years = years + forecast_years\n",
    "        all_values = values + forecast_values\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Historical data\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=years,\n",
    "            y=values,\n",
    "            mode='lines+markers',\n",
    "            name='Historical',\n",
    "            line=dict(color='blue', width=3),\n",
    "            marker=dict(size=8)\n",
    "        ))\n",
    "        \n",
    "        # Forecast\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=forecast_years,\n",
    "            y=forecast_values,\n",
    "            mode='lines+markers',\n",
    "            name='Forecast',\n",
    "            line=dict(color='red', width=3, dash='dash'),\n",
    "            marker=dict(size=8, symbol='diamond')\n",
    "        ))\n",
    "        \n",
    "        # Add threshold lines\n",
    "        fig.add_hline(y=100, line_dash=\"dot\", line_color=\"red\", \n",
    "                     annotation_text=\"Critical Threshold (100%)\", \n",
    "                     annotation_position=\"bottom right\")\n",
    "        fig.add_hline(y=50, line_dash=\"dot\", line_color=\"orange\", \n",
    "                     annotation_text=\"High Stress (50%)\", \n",
    "                     annotation_position=\"top right\")\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f' Water Withdrawal Forecast for {country_name}',\n",
    "            xaxis_title='Year',\n",
    "            yaxis_title='Withdrawal (% of Internal Resources)',\n",
    "            height=500,\n",
    "            hovermode='x unified'\n",
    "        )\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c753b8-1719-4e36-b809-9d7e5be5872d",
   "metadata": {},
   "outputs": [],
   "source": [
    " System Initialization\n",
    "print(\" INITIALIZING AI-POWERED WATER CRISIS PREDICTION SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize the system\n",
    "filepath = \"API_ER.H2O.FWTL.ZS_DS2_en_csv_v2_4288.csv\"  # Update with your file path\n",
    "\n",
    "# Step 1: Process data with AI features\n",
    "processor = WaterCrisisAIDataProcessor(filepath)\n",
    "df_features = processor.load_and_engineer_features()\n",
    "\n",
    "print(f\"\\n Data Summary:\")\n",
    "print(f\"‚Ä¢ Countries analyzed: {len(df_features)}\")\n",
    "print(f\"‚Ä¢ Features created: {len(df_features.columns)}\")\n",
    "print(f\"‚Ä¢ Average risk score: {df_features['crisis_risk_score'].mean():.1f}\")\n",
    "\n",
    "# Step 2: Initialize AI predictor\n",
    "predictor = WaterCrisisPredictor(processor)\n",
    "\n",
    "# Step 3: Run all AI analyses\n",
    "print(\"\\n RUNNING AI ANALYSES...\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# 1. Predict crisis risks\n",
    "high_risk_countries = predictor.predict_crisis_risk(forecast_years=5)\n",
    "print(f\"1Ô∏è‚É£ Crisis Prediction: {len(high_risk_countries)} high-risk countries identified\")\n",
    "\n",
    "# 2. Cluster countries\n",
    "clusters, cluster_analysis = predictor.cluster_countries(n_clusters=5)\n",
    "print(f\"2Ô∏è‚É£ Country Clustering: 5 distinct patterns identified\")\n",
    "\n",
    "# 3. Detect anomalies\n",
    "anomalous_countries = predictor.detect_anomalies(contamination=0.1)\n",
    "print(f\"3Ô∏è‚É£ Anomaly Detection: {len(anomalous_countries)} unusual patterns found\")\n",
    "\n",
    "# Step 4: Initialize visualizer\n",
    "visualizer = WaterCrisisVisualizer(predictor)\n",
    "\n",
    "print(\"\\n AI SYSTEM INITIALIZED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0aa60-bcd8-4bb7-aeca-d5d4e599027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Interactive Analysis Interface\n",
    "def interactive_ai_analysis():\n",
    "    \"\"\"Interactive interface for exploring AI insights\"\"\"\n",
    "    \n",
    "    print(\" AI-POWERED WATER CRISIS ANALYSIS INTERFACE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nAvailable Functions:\")\n",
    "    print(\"1.  View global risk map\")\n",
    "    print(\"2.  See crisis predictions\")\n",
    "    print(\"3.  Explore country clusters\")\n",
    "    print(\"4.  Check anomaly detection\")\n",
    "    print(\"5.  Get country-specific analysis\")\n",
    "    print(\"6.  Get recommendations for a country\")\n",
    "    print(\"7.  View forecast for a country\")\n",
    "    print(\"8.  Export all AI insights\")\n",
    "    print(\"\\nType 'exit' to quit\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nEnter your choice (1-8): \").strip()\n",
    "        \n",
    "        if choice.lower() == 'exit':\n",
    "            print(\" Exiting AI analysis interface\")\n",
    "            break\n",
    "        \n",
    "        elif choice == '1':\n",
    "            print(\" Generating global risk map...\")\n",
    "            fig = visualizer.plot_risk_map()\n",
    "            fig.show()\n",
    "            \n",
    "        elif choice == '2':\n",
    "            print(\"  Displaying crisis predictions...\")\n",
    "            fig = visualizer.plot_crisis_predictions()\n",
    "            fig.show()\n",
    "            \n",
    "            # Show top 5 high-risk countries\n",
    "            print(\"\\n Top 5 Highest Risk Countries:\")\n",
    "            top_5 = predictor.df_features.sort_values('crisis_probability', ascending=False).head(5)\n",
    "            for idx, row in top_5.iterrows():\n",
    "                print(f\"  {row['country']}: {row['crisis_probability']:.3f} probability\")\n",
    "                \n",
    "        elif choice == '3':\n",
    "            print(\" Displaying country clusters...\")\n",
    "            fig = visualizer.plot_cluster_analysis()\n",
    "            fig.show()\n",
    "            \n",
    "            # Show cluster descriptions\n",
    "            print(\"\\n Cluster Descriptions:\")\n",
    "            for cluster_id, analysis in cluster_analysis.items():\n",
    "                print(f\"\\nCluster {cluster_id}: {analysis['characteristics']}\")\n",
    "                print(f\"  Countries: {', '.join(analysis['countries'][:5])}...\")\n",
    "                \n",
    "        elif choice == '4':\n",
    "            print(\"üîç Displaying anomaly detection...\")\n",
    "            fig = visualizer.plot_anomaly_detection()\n",
    "            fig.show()\n",
    "            \n",
    "            print(f\"\\n  Anomalous Countries ({len(anomalous_countries)}):\")\n",
    "            for country in anomalous_countries[:10]:  # Show first 10\n",
    "                print(f\"  ‚Ä¢ {country}\")\n",
    "            if len(anomalous_countries) > 10:\n",
    "                print(f\"  ... and {len(anomalous_countries) - 10} more\")\n",
    "                \n",
    "        elif choice == '5':\n",
    "            country = input(\"Enter country name: \").strip()\n",
    "            if country in predictor.df_features['country'].values:\n",
    "                country_data = predictor.df_features[predictor.df_features['country'] == country].iloc[0]\n",
    "                \n",
    "                print(f\"\\n AI ANALYSIS FOR: {country}\")\n",
    "                print(\"-\"*40)\n",
    "                print(f\"Current Withdrawal: {country_data['latest_value']:.1f}%\")\n",
    "                print(f\"Risk Score: {country_data['crisis_risk_score']:.1f}/100\")\n",
    "                print(f\"Crisis Probability: {country_data.get('crisis_probability', 0):.3f}\")\n",
    "                print(f\"Trend: {country_data['trend_slope']:.3f} (positive = increasing)\")\n",
    "                print(f\"Cluster: {int(country_data['cluster'])}\")\n",
    "                print(f\"Anomaly: {'YES' if country_data.get('is_anomaly', 0) == 1 else 'NO'}\")\n",
    "                \n",
    "                # Get forecast\n",
    "                if 'forecast_5yr' in country_data:\n",
    "                    print(f\"5-Year Forecast: {country_data['forecast_5yr']:.1f}%\")\n",
    "                    if country_data['forecast_5yr'] > 100:\n",
    "                        print(\"  Forecast exceeds 100% - CRITICAL RISK\")\n",
    "                        \n",
    "            else:\n",
    "                print(f\"Country '{country}' not found in data\")\n",
    "                \n",
    "        elif choice == '6':\n",
    "            country = input(\"Enter country name for recommendations: \").strip()\n",
    "            recommendations = predictor.get_recommendations(country, n_recommendations=3)\n",
    "            print(f\"\\n RECOMMENDATIONS FOR {country.upper()}:\")\n",
    "            print(\"-\"*40)\n",
    "            print(recommendations)\n",
    "            \n",
    "        elif choice == '7':\n",
    "            country = input(\"Enter country name for forecast: \").strip()\n",
    "            fig = visualizer.plot_trajectory_forecast(country, years_ahead=10)\n",
    "            if fig:\n",
    "                fig.show()\n",
    "            else:\n",
    "                print(f\"Could not generate forecast for {country}\")\n",
    "                \n",
    "        elif choice == '8':\n",
    "            print(\" Exporting AI insights...\")\n",
    "            export_ai_insights(predictor)\n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1-8 or 'exit'\")\n",
    "\n",
    "def export_ai_insights(predictor):\n",
    "    \"\"\"Export all AI insights to files\"\"\"\n",
    "    import json\n",
    "    \n",
    "    timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Export predictions\n",
    "    predictions_df = predictor.df_features[[\n",
    "        'country', 'latest_value', 'crisis_risk_score', \n",
    "        'crisis_probability', 'predicted_crisis', 'cluster',\n",
    "        'is_anomaly', 'forecast_5yr'\n",
    "    ]]\n",
    "    predictions_df.to_csv(f'water_crisis_predictions_{timestamp}.csv', index=False)\n",
    "    \n",
    "    # 2. Export high-risk countries\n",
    "    high_risk = predictor.df_features[\n",
    "        predictor.df_features['crisis_probability'] > 0.7\n",
    "    ][['country', 'crisis_probability', 'latest_value', 'trend_slope']]\n",
    "    high_risk.to_csv(f'high_risk_countries_{timestamp}.csv', index=False)\n",
    "    \n",
    "    # 3. Export cluster analysis\n",
    "    cluster_summary = []\n",
    "    for cluster_id in range(5):\n",
    "        cluster_data = predictor.df_features[predictor.df_features['cluster'] == cluster_id]\n",
    "        cluster_summary.append({\n",
    "            'cluster': cluster_id,\n",
    "            'count': len(cluster_data),\n",
    "            'avg_withdrawal': cluster_data['latest_value'].mean(),\n",
    "            'avg_risk': cluster_data['crisis_risk_score'].mean(),\n",
    "            'representative_countries': cluster_data['country'].head(5).tolist()\n",
    "        })\n",
    "    \n",
    "    with open(f'cluster_analysis_{timestamp}.json', 'w') as f:\n",
    "        json.dump(cluster_summary, f, indent=2)\n",
    "    \n",
    "    # 4. Export anomalies\n",
    "    anomalies = predictor.df_features[\n",
    "        predictor.df_features['is_anomaly'] == 1\n",
    "    ][['country', 'latest_value', 'trend_slope', 'anomaly_score']]\n",
    "    anomalies.to_csv(f'anomalous_countries_{timestamp}.csv', index=False)\n",
    "    \n",
    "    print(f\" AI insights exported with timestamp: {timestamp}\")\n",
    "    print(f\" Files created:\")\n",
    "    print(f\"  ‚Ä¢ water_crisis_predictions_{timestamp}.csv\")\n",
    "    print(f\"  ‚Ä¢ high_risk_countries_{timestamp}.csv\")\n",
    "    print(f\"  ‚Ä¢ cluster_analysis_{timestamp}.json\")\n",
    "    print(f\"  ‚Ä¢ anomalous_countries_{timestamp}.csv\")\n",
    "\n",
    "# Run the interactive interface\n",
    "interactive_ai_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521461b-e194-4f85-b7cf-f9be566b6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: Example AI Insights Summary\n",
    "print(\" AI INSIGHTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n1Ô∏è‚É£ CRISIS PREDICTION SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Total countries analyzed: {len(predictor.df_features)}\")\n",
    "print(f\"   ‚Ä¢ High-risk countries (prob > 0.7): {len(predictor.df_features[predictor.df_features['crisis_probability'] > 0.7])}\")\n",
    "print(f\"   ‚Ä¢ Critical countries (withdrawal > 100%): {len(predictor.df_features[predictor.df_features['latest_value'] > 100])}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ CLUSTERING SUMMARY:\")\n",
    "for cluster_id in range(5):\n",
    "    cluster_size = len(predictor.df_features[predictor.df_features['cluster'] == cluster_id])\n",
    "    cluster_avg = predictor.df_features[predictor.df_features['cluster'] == cluster_id]['latest_value'].mean()\n",
    "    print(f\"   ‚Ä¢ Cluster {cluster_id}: {cluster_size} countries, avg withdrawal: {cluster_avg:.1f}%\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ ANOMALY DETECTION:\")\n",
    "print(f\"   ‚Ä¢ Anomalous countries detected: {len(anomalous_countries)}\")\n",
    "print(f\"   ‚Ä¢ Example anomalies: {', '.join(anomalous_countries[:3])}\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ TOP 5 HIGHEST RISK COUNTRIES:\")\n",
    "top_risks = predictor.df_features.sort_values('crisis_probability', ascending=False).head(5)\n",
    "for idx, row in top_risks.iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['country']}: Risk={row['crisis_risk_score']:.1f}, Prob={row['crisis_probability']:.3f}\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ RECOMMENDATION EXAMPLES:\")\n",
    "sample_countries = ['India', 'China', 'United States', 'Saudi Arabia']\n",
    "for country in sample_countries:\n",
    "    if country in predictor.df_features['country'].values:\n",
    "        risk = predictor.df_features[predictor.df_features['country'] == country]['crisis_risk_score'].values[0]\n",
    "        prob = predictor.df_features[predictor.df_features['country'] == country]['crisis_probability'].values[0]\n",
    "        print(f\"   ‚Ä¢ {country}: Risk={risk:.1f}, Crisis Probability={prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67eab4-fdf2-4e9e-90bd-ff47d617e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Model Evaluation and Explainability\n",
    "class AI_Model_Evaluator:\n",
    "    \"\"\"\n",
    "    Evaluate and explain AI model predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "        self.df_features = predictor.df_features\n",
    "        \n",
    "    def evaluate_model_performance(self):\n",
    "        \"\"\"Evaluate the AI model's performance\"\"\"\n",
    "        from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        # Prepare data\n",
    "        X = self.predictor._prepare_prediction_features()\n",
    "        y_true = (self.df_features['crisis_risk_score'] > 70).astype(int)\n",
    "        \n",
    "        # Get predictions from Random Forest\n",
    "        rf_model = self.predictor.models.get('random_forest')\n",
    "        if rf_model:\n",
    "            y_pred = rf_model.predict(X)\n",
    "            y_pred_proba = rf_model.predict_proba(X)[:, 1]\n",
    "            \n",
    "            print(\" RANDOM FOREST MODEL EVALUATION:\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "            # Classification report\n",
    "            print(\"\\n Classification Report:\")\n",
    "            print(classification_report(y_true, y_pred, target_names=['Low Risk', 'High Risk']))\n",
    "            \n",
    "            # ROC-AUC Score\n",
    "            roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "            print(f\" ROC-AUC Score: {roc_auc:.3f}\")\n",
    "            \n",
    "            # Feature importance\n",
    "            self._plot_feature_importance(rf_model)\n",
    "            \n",
    "            return roc_auc\n",
    "    \n",
    "    def _plot_feature_importance(self, model):\n",
    "        \"\"\"Plot feature importance from Random Forest\"\"\"\n",
    "        feature_names = [\n",
    "            'latest_value', 'trend_slope', 'volatility', 'max_value',\n",
    "            'mean_value', 'pct_change_10yr', 'pct_change_20yr',\n",
    "            'crisis_risk_score', 'acceleration', 'skewness', 'kurtosis',\n",
    "            'iqr', 'cv'\n",
    "        ]\n",
    "        \n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Feature Importance in Crisis Prediction\")\n",
    "        plt.bar(range(len(indices)), importances[indices])\n",
    "        plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "        plt.ylabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print top 5 features\n",
    "        print(\"\\n Top 5 Most Important Features:\")\n",
    "        for i in range(5):\n",
    "            print(f\"  {i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.3f}\")\n",
    "    \n",
    "    def explain_prediction(self, country_name):\n",
    "        \"\"\"Explain why a specific country is predicted as high-risk\"\"\"\n",
    "        import shap\n",
    "        \n",
    "        if country_name not in self.df_features['country'].values:\n",
    "            return f\"Country {country_name} not found\"\n",
    "        \n",
    "        # Get the model\n",
    "        rf_model = self.predictor.models.get('random_forest')\n",
    "        if not rf_model:\n",
    "            return \"Model not trained yet\"\n",
    "        \n",
    "        # Prepare data\n",
    "        X = self.predictor._prepare_prediction_features()\n",
    "        country_idx = self.df_features[self.df_features['country'] == country_name].index[0]\n",
    "        \n",
    "        # Create SHAP explainer\n",
    "        explainer = shap.TreeExplainer(rf_model)\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        \n",
    "        # Get prediction for this country\n",
    "        prediction = rf_model.predict_proba(X[country_idx:country_idx+1])[0, 1]\n",
    "        \n",
    "        print(f\" PREDICTION EXPLANATION FOR: {country_name}\")\n",
    "        print(f\"   Crisis Probability: {prediction:.3f}\")\n",
    "        print(\"\\n Feature Contributions:\")\n",
    "        \n",
    "        # Feature contributions\n",
    "        feature_names = [\n",
    "            'Current Withdrawal', 'Trend Slope', 'Volatility', 'Max Value',\n",
    "            'Mean Value', '10Y Change %', '20Y Change %',\n",
    "            'Risk Score', 'Acceleration', 'Skewness', 'Kurtosis',\n",
    "            'IQR', 'CV'\n",
    "        ]\n",
    "        \n",
    "        # Get SHAP values for this instance\n",
    "        shap_val = shap_values[1][country_idx]  # Class 1 (crisis)\n",
    "        \n",
    "        # Sort by absolute contribution\n",
    "        contributions = sorted(zip(feature_names, shap_val), key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        for feature, contribution in contributions[:5]:  # Top 5 contributors\n",
    "            direction = \"increases\" if contribution > 0 else \"decreases\"\n",
    "            print(f\"   ‚Ä¢ {feature}: {contribution:.3f} ({direction} crisis risk)\")\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "# Initialize and run evaluation\n",
    "print(\" MODEL EVALUATION AND EXPLAINABILITY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluator = AI_Model_Evaluator(predictor)\n",
    "roc_auc = evaluator.evaluate_model_performance()\n",
    "\n",
    "# Explain predictions for sample countries\n",
    "print(\"\\n EXPLAINING PREDICTIONS:\")\n",
    "sample_countries = ['Saudi Arabia', 'United Arab Emirates', 'Qatar']\n",
    "for country in sample_countries:\n",
    "    if country in predictor.df_features['country'].values:\n",
    "        print(f\"\\n{'-'*40}\")\n",
    "        evaluator.explain_prediction(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd046a0-7ff3-49d0-a082-b7e7309c4814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e0c3d1-6751-422c-9de3-c23b09daa3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
